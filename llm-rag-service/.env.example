# LLM/RAG Service Environment Configuration

# Server Configuration
PORT=3003
NODE_ENV=development
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001,http://localhost:3002

# Database Configuration
DATABASE_URL="file:./dev.db"

# Authentication Configuration
DISABLE_AUTH=true
JWT_SECRET=your-jwt-secret-key-here
API_KEY_PREFIX=llm-rag

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_ORG_ID=your-openai-org-id-here

# LLM Configuration
LLM_PROVIDER=openai
LLM_MODEL=gpt-3.5-turbo
LLM_ENDPOINT=https://api.openai.com/v1
LLM_MAX_TOKENS=4000
LLM_TEMPERATURE=0.7

# Embedding Configuration
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=text-embedding-ada-002
EMBEDDING_ENDPOINT=https://api.openai.com/v1
EMBEDDING_DIMENSIONS=1536

# Pinecone Configuration (Vector Database)
PINECONE_API_KEY=your-pinecone-api-key-here
PINECONE_ENVIRONMENT=your-pinecone-environment
PINECONE_INDEX_NAME=llm-rag-embeddings
PINECONE_NAMESPACE=default

# Alternative Vector Database Configurations
# VECTOR_DB_PROVIDER=pinecone  # pinecone, weaviate, qdrant
# WEAVIATE_URL=http://localhost:8080
# WEAVIATE_API_KEY=your-weaviate-key
# QDRANT_URL=http://localhost:6333
# QDRANT_API_KEY=your-qdrant-key

# Knowledge Graph Service Integration
KNOWLEDGE_GRAPH_URL=http://localhost:3001
KNOWLEDGE_GRAPH_API_KEY=your-kg-api-key-here

# Service Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_SEARCH_RESULTS=50
SIMILARITY_THRESHOLD=0.7
RERANKING_ENABLED=true

# Rate Limiting
RATE_LIMIT_WINDOW_MS=900000  # 15 minutes
RATE_LIMIT_MAX_REQUESTS=100  # requests per window

# Logging Configuration
LOG_LEVEL=info
LOG_FORMAT=combined

# Health Check Configuration
HEALTH_CHECK_INTERVAL=30000  # 30 seconds

# Cache Configuration
REDIS_URL=redis://localhost:6379
CACHE_TTL=3600  # 1 hour
ENABLE_CACHING=false

# Message Bus Configuration
SERVICE_BUS_CONNECTION_STRING=Endpoint=sb://your-service-bus.servicebus.windows.net/;SharedAccessKeyName=...
SERVICE_BUS_TOPIC_NAME=cognisync-events
SERVICE_BUS_SUBSCRIPTION_NAME=llm-rag-subscription
REDIS_CHANNEL_PREFIX=cognisync

# Monitoring Configuration
ENABLE_METRICS=true
METRICS_PORT=9090
ENABLE_TRACING=false

# Performance Configuration
MAX_CONCURRENT_REQUESTS=10
REQUEST_TIMEOUT=30000  # 30 seconds
BATCH_SIZE=20
MAX_EMBEDDING_BATCH_SIZE=100

# Development Configuration
DEBUG=false
VERBOSE_LOGGING=false
ENABLE_CORS=true
TRUST_PROXY=false

# Production Configuration (override in production)
# NODE_ENV=production
# DISABLE_AUTH=false
# ALLOWED_ORIGINS=https://your-domain.com
# DATABASE_URL=postgresql://user:password@localhost:5432/llm_rag
# LOG_LEVEL=error
# ENABLE_CACHING=true
# TRUST_PROXY=true
